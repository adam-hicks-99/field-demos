{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63204697-8525-40bf-aef3-d60b286b9c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "\n",
    "# Read the model-level report table\n",
    "try:\n",
    "    report_df = spark.table(\"field_demos.ml_ops.master_model_report\")\n",
    "except Exception as e:\n",
    "    print(\"Error reading master_model_report table:\", e)\n",
    "    dbutils.jobs.taskValues.set(key=\"retrain_candidates\", value=[])\n",
    "    raise e\n",
    "\n",
    "# Filter models that need retraining and collect their names\n",
    "models_to_retrain = report_df.filter(\"needs_retrained = true\").select(\"model_name\").collect()\n",
    "candidates = [row[\"model_name\"] for row in models_to_retrain]\n",
    "\n",
    "# Build retraining candidate log events\n",
    "retrain_logs = []\n",
    "current_time = datetime.datetime.now()\n",
    "for model_name in candidates:\n",
    "    retrain_logs.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"retrain_time\": current_time,\n",
    "        \"status\": \"Candidate flagged\",\n",
    "        \"details\": f\"Model {model_name} flagged for retraining.\"\n",
    "    })\n",
    "\n",
    "# If any retraining candidates were found, write log events to a Delta table\n",
    "if retrain_logs:\n",
    "    log_schema = StructType([\n",
    "        StructField(\"model_name\", StringType(), True),\n",
    "        StructField(\"retrain_time\", TimestampType(), True),\n",
    "        StructField(\"status\", StringType(), True),\n",
    "        StructField(\"details\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    log_df = spark.createDataFrame(retrain_logs, schema=log_schema)\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"field_demos.ml_ops.model_retrain_log\")\n",
    "    print(\"Retraining candidate events logged to Delta table 'field_demos.ml_ops.model_retrain_log'.\")\n",
    "else:\n",
    "    print(\"No models flagged for retraining.\")\n",
    "\n",
    "# Pass the list of candidate model_ids to the next job task\n",
    "dbutils.jobs.taskValues.set(key=\"retrain_candidates\", value=candidates)\n",
    "print(\"Candidates to retrain passed to next job:\", candidates)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7950742759226996,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Identify Retraining Candidates",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
